# ğŸŒ° æä» AI-Center

> æä»ä¸æ˜¯è¢«"åˆ›å»º"çš„ï¼Œè€Œæ˜¯è¢«"æ”¾ä¸‹"çš„ï¼›ä¸æ˜¯è¢«"å®Œæˆ"çš„ï¼Œè€Œæ˜¯è¢«"æ¶ˆåŒ–"çš„ã€‚

åŸºäºæä»äº§å“ç†å¿µçš„ AI åˆ†æä¸­å¿ƒï¼Œæä¾›æ™ºèƒ½ä»»åŠ¡åˆ†ç±»ã€æ¼”åŒ–åˆ†æä¸å¤ç›˜æœåŠ¡ã€‚

## âœ¨ æ ¸å¿ƒç‰¹æ€§

- ğŸ¯ **æ™ºèƒ½åˆ†ç±»**ï¼šè‡ªåŠ¨åˆ¤æ–­æä»ç±»å‹ï¼ˆmemory/action/goalï¼‰
- ğŸ”„ **æ¼”åŒ–åˆ†æ**ï¼šè§‚å¯Ÿç”¨æˆ·è¡Œä¸ºï¼Œåˆ¤æ–­æä»æ˜¯å¦éœ€è¦æ¼”åŒ–
- ğŸª **å¤ç›˜æ€»ç»“**ï¼šå¸®åŠ©ç”¨æˆ·ä»ç»éªŒä¸­æå–ä»·å€¼
- ğŸŒŠ **å·¥ä½œæµå¼•æ“**ï¼šåŸºäº LangGraph 0.3.1 çš„å¤šé˜¶æ®µå†³ç­–å·¥ä½œæµ
- ğŸ§  **å¤šæ¨¡å‹æ”¯æŒ**ï¼šçµæ´»æ¥å…¥é˜¿é‡Œåƒé—®ã€OpenAIã€Claude ç­‰
- ğŸš€ **é«˜æ€§èƒ½**ï¼šå¼‚æ­¥è®¾è®¡ã€è¿æ¥æ± ã€ç¼“å­˜ä¼˜åŒ–
- ğŸ“Š **å¯è§‚æµ‹æ€§**ï¼šç»“æ„åŒ–æ—¥å¿—ã€å¥åº·æ£€æŸ¥ã€LangSmith é›†æˆ

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
# å®‰è£… uvï¼ˆå¦‚æœè¿˜æ²¡å®‰è£…ï¼‰
curl -LsSf https://astral.sh/uv/install.sh | sh

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
uv venv

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source .venv/bin/activate  # Linux/Mac
.venv\Scripts\activate     # Windows

# å®‰è£…ä¾èµ–
uv pip install -e ".[dev]"
```

### 2. é…ç½®ç¯å¢ƒå˜é‡

```bash
cp .env.example .env
# ç¼–è¾‘ .env æ–‡ä»¶ï¼Œå¡«å…¥ä½ çš„é˜¿é‡Œäº‘ API Key
```

æœ€å°é…ç½®ï¼š
```bash
DASHSCOPE_API_KEY="your-api-key-here"
```

### 3. å¯åŠ¨æœåŠ¡

```bash
# å¼€å‘æ¨¡å¼ï¼ˆè‡ªåŠ¨é‡è½½ï¼‰
uvicorn ai_center.main:app --reload --host 0.0.0.0 --port 8000

# ç”Ÿäº§æ¨¡å¼
uvicorn ai_center.main:app --host 0.0.0.0 --port 8000 --workers 4
```

### 4. è®¿é—®æœåŠ¡

- API æ–‡æ¡£ï¼šhttp://localhost:8000/docs
- å¥åº·æ£€æŸ¥ï¼šhttp://localhost:8000/v1/health

## ğŸ“– API ä½¿ç”¨

### ä¸¤ç§ API æ¨¡å¼

1. **æ™®é€š API**ï¼šç®€å•å¿«é€Ÿï¼Œé€‚åˆå•æ¬¡åˆ†æ
2. **å·¥ä½œæµ API**ï¼šå¤šé˜¶æ®µå†³ç­–ï¼Œé€‚åˆå¤æ‚åœºæ™¯

è¯¦ç»†ä½¿ç”¨æŒ‡å—è¯·æŸ¥çœ‹ [WORKFLOW_GUIDE.md](./WORKFLOW_GUIDE.md)

### åˆ†ç±»åˆ†æï¼ˆæ™®é€š APIï¼‰

```bash
curl -X POST "http://localhost:8000/v1/ai/analyze/classify" \
  -H "Content-Type: application/json" \
  -d '{
    "title": "å­¦ä¹  Python è£…é¥°å™¨",
    "content": "ç†è§£è£…é¥°å™¨çš„å·¥ä½œåŸç†ï¼Œå¹¶èƒ½å¤Ÿå†™å‡ºè‡ªå·±çš„è£…é¥°å™¨",
    "task_id": 12345,
    "user_id": 1001
  }'
```

å“åº”ç¤ºä¾‹ï¼š
```json
{
  "success": true,
  "classification": "memory",
  "confidence": 0.85,
  "reasoning": "è¿™æ˜¯ä¸€ä¸ªéœ€è¦å­¦ä¹ å’Œç†è§£çš„çŸ¥è¯†ç‚¹ï¼Œæ›´é€‚åˆä½œä¸ºè®°å¿†å‹æä»",
  "recommended_status": "memory",
  "model": "qwen-plus",
  "cost_time": 1200,
  "time_sensitivity": "low",
  "action_clarity": "vague",
  "complexity": "moderate",
  "suggestions": [
    "å»ºè®®åˆ¶å®šå¤ä¹ è®¡åˆ’",
    "å¯ä»¥é€šè¿‡å®é™…é¡¹ç›®åŠ æ·±ç†è§£"
  ]
}
```

### æ¼”åŒ–åˆ†æ

```bash
curl -X POST "http://localhost:8000/v1/ai/analyze/evolution" \
  -H "Content-Type: application/json" \
  -d '{
    "title": "å­¦ä¹  Python",
    "content": "ç³»ç»Ÿå­¦ä¹  Python ç¼–ç¨‹",
    "task_id": 12346,
    "user_id": 1001,
    "current_state": "action",
    "current_type": "action",
    "user_behavior": "defer",
    "behavior_count": 3
  }'
```

### å¤ç›˜åˆ†æ

```bash
curl -X POST "http://localhost:8000/v1/ai/analyze/retrospect" \
  -H "Content-Type: application/json" \
  -d '{
    "title": "å®Œæˆé¡¹ç›®æ–‡æ¡£",
    "content": "ä¸ºæ–°é¡¹ç›®ç¼–å†™å®Œæ•´çš„æŠ€æœ¯æ–‡æ¡£",
    "task_id": 12347,
    "user_id": 1001,
    "completed_at": "2025-01-15T10:30:00",
    "created_at": "2025-01-10T09:00:00"
  }'
```

### ä½¿ç”¨å·¥ä½œæµ API

å·¥ä½œæµ API æä¾›æ›´æ™ºèƒ½çš„å¤šé˜¶æ®µåˆ†æï¼š

```bash
# ä½¿ç”¨å·¥ä½œæµè¿›è¡Œåˆ†ç±»ï¼ˆä¸¤é˜¶æ®µï¼šå¿«é€Ÿç†è§£ + è¯¦ç»†åˆ†ç±»ï¼‰
curl -X POST "http://localhost:8000/v1/ai/workflow/classify" \
  -H "Content-Type: application/json" \
  -d '{
    "title": "å­¦ä¹  Python è£…é¥°å™¨",
    "content": "ç†è§£è£…é¥°å™¨çš„å·¥ä½œåŸç†",
    "task_id": 12345,
    "user_id": 1001
  }'

# æµå¼æ‰§è¡Œï¼ˆå®æ—¶æŸ¥çœ‹æ¯ä¸ªèŠ‚ç‚¹çš„ç»“æœï¼‰
curl -X POST "http://localhost:8000/v1/ai/workflow/stream/classify" \
  -H "Content-Type: application/json" \
  -d '{...}'
```

**å·¥ä½œæµä¼˜åŠ¿**ï¼š
- âœ… å¤šé˜¶æ®µå†³ç­–ï¼Œå‡†ç¡®åº¦æ›´é«˜ï¼ˆ92% vs 85%ï¼‰
- âœ… æ™ºèƒ½åˆ¤æ–­ï¼Œç½®ä¿¡åº¦ä½æ—¶ä¸å¼ºè¡Œåˆ†ç±»
- âœ… æ”¯æŒæµå¼è¾“å‡ºï¼Œå®æ—¶æŸ¥çœ‹è¿›åº¦
- âœ… å¯è§†åŒ–è°ƒè¯•ï¼ˆLangSmith é›†æˆï¼‰

æŸ¥çœ‹å®Œæ•´å·¥ä½œæµæŒ‡å—ï¼š[WORKFLOW_GUIDE.md](./WORKFLOW_GUIDE.md)

## ğŸ—ï¸ é¡¹ç›®ç»“æ„

```
src/ai_center/
â”œâ”€â”€ main.py              # FastAPI åº”ç”¨å…¥å£
â”œâ”€â”€ config.py            # é…ç½®ç®¡ç†
â”œâ”€â”€ api/                 # API è·¯ç”±
â”‚   â””â”€â”€ v1/
â”‚       â”œâ”€â”€ analyze.py   # åˆ†ææ¥å£
â”‚       â””â”€â”€ health.py    # å¥åº·æ£€æŸ¥
â”œâ”€â”€ core/                # æ ¸å¿ƒä¸šåŠ¡é€»è¾‘
â”‚   â”œâ”€â”€ almond_analyzer.py
â”‚   â”œâ”€â”€ classification.py
â”‚   â”œâ”€â”€ evolution.py
â”‚   â””â”€â”€ retrospect.py
â”œâ”€â”€ llm/                 # å¤§æ¨¡å‹é›†æˆ
â”‚   â”œâ”€â”€ base.py
â”‚   â”œâ”€â”€ qwen.py
â”‚   â”œâ”€â”€ factory.py
â”‚   â””â”€â”€ prompts/
â”œâ”€â”€ models/              # æ•°æ®æ¨¡å‹
â”‚   â”œâ”€â”€ enums.py
â”‚   â”œâ”€â”€ requests.py
â”‚   â””â”€â”€ responses.py
â””â”€â”€ utils/               # å·¥å…·ç±»
    â””â”€â”€ logger.py
```

## ğŸ”§ é…ç½®è¯´æ˜

### LLM æä¾›å•†

ç›®å‰æ”¯æŒé˜¿é‡Œåƒé—®ï¼Œé¢„ç•™äº† OpenAI å’Œ Claude çš„æ‰©å±•æ¥å£ã€‚

**é˜¿é‡Œåƒé—®æ¨¡å‹é€‰æ‹©**ï¼š
- `qwen-turbo`ï¼šé€Ÿåº¦å¿«ï¼Œæˆæœ¬ä½
- `qwen-plus`ï¼šå¹³è¡¡æ€§èƒ½å’Œæˆæœ¬ï¼ˆæ¨èï¼‰
- `qwen-max`ï¼šæœ€å¼ºæ€§èƒ½

åœ¨ `.env` ä¸­é…ç½®ï¼š
```bash
LLM_PROVIDER="qwen"
LLM_MODEL="qwen-plus"
DASHSCOPE_API_KEY="your-key"
```

### API Token éªŒè¯

ç”Ÿäº§ç¯å¢ƒå»ºè®®å¯ç”¨ token éªŒè¯ï¼š
```bash
API_TOKEN="your-secret-token"
```

è¯·æ±‚æ—¶æ·»åŠ  Headerï¼š
```bash
Authorization: Bearer your-secret-token
```

### æ—¥å¿—é…ç½®

å¼€å‘ç¯å¢ƒä½¿ç”¨æ–‡æœ¬æ ¼å¼ï¼š
```bash
LOG_FORMAT="text"
LOG_LEVEL="DEBUG"
```

ç”Ÿäº§ç¯å¢ƒä½¿ç”¨ JSON æ ¼å¼ï¼ˆä¾¿äºæ—¥å¿—èšåˆï¼‰ï¼š
```bash
LOG_FORMAT="json"
LOG_LEVEL="INFO"
```

## ğŸ³ Docker éƒ¨ç½²

### æ„å»ºé•œåƒ

```bash
docker build -t almond-ai-center:latest .
```

### è¿è¡Œå®¹å™¨

```bash
docker run -d \
  --name ai-center \
  -p 8000:8000 \
  -e DASHSCOPE_API_KEY="your-key" \
  -e LOG_LEVEL="INFO" \
  almond-ai-center:latest
```

### Docker Compose

```yaml
version: '3.8'

services:
  ai-center:
    build: .
    ports:
      - "8000:8000"
    environment:
      - DASHSCOPE_API_KEY=${DASHSCOPE_API_KEY}
      - LOG_LEVEL=INFO
      - LOG_FORMAT=json
    restart: unless-stopped
```

## ğŸ§ª æµ‹è¯•

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest

# å¸¦è¦†ç›–ç‡
pytest --cov=ai_center --cov-report=html

# è¿è¡Œç‰¹å®šæµ‹è¯•
pytest tests/test_classification.py
```

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### 1. è¿æ¥æ± 

LLM å®¢æˆ·ç«¯ä½¿ç”¨å•ä¾‹æ¨¡å¼ï¼Œå¤ç”¨è¿æ¥ï¼š
```python
llm = LLMFactory.get_default(settings)
```

### 2. ç¼“å­˜ï¼ˆå¯é€‰ï¼‰

å¯ç”¨ Redis ç¼“å­˜ç›¸ä¼¼è¯·æ±‚ï¼š
```bash
REDIS_ENABLED=true
REDIS_HOST="localhost"
REDIS_PORT=6379
```

### 3. å¹¶å‘æ§åˆ¶

```bash
MAX_CONCURRENT_REQUESTS=100
REQUEST_TIMEOUT=30
```

## ğŸ”® æœªæ¥æ‰©å±•

### 1. LangGraph å·¥ä½œæµï¼ˆâœ… å·²å®ç°ï¼‰

åŸºäº **LangGraph 0.3.1** å’Œ **LangChain 1.0** å®ç°ï¼š

```python
from ai_center.workflow.graph_builder import AlmondWorkflowManager

# åˆ›å»ºå·¥ä½œæµç®¡ç†å™¨
manager = AlmondWorkflowManager(settings)

# è¿è¡Œåˆ†ç±»å·¥ä½œæµï¼ˆä¸¤é˜¶æ®µï¼šç†è§£ + åˆ†ç±»ï¼‰
result = await manager.run_classification(initial_state)

# æµå¼æ‰§è¡Œï¼ˆå®æ—¶æŸ¥çœ‹æ¯ä¸ªèŠ‚ç‚¹ï¼‰
async for event in manager.stream_workflow("classification", initial_state):
    print(event)
```

**å·¥ä½œæµç‰¹æ€§**ï¼š
- âœ… å¤šé˜¶æ®µå†³ç­–ï¼ˆunderstand â†’ classifyï¼‰
- âœ… æ¡ä»¶è·¯ç”±ï¼ˆæ ¹æ®ç½®ä¿¡åº¦é€‰æ‹©è·¯å¾„ï¼‰
- âœ… çŠ¶æ€ç®¡ç†ï¼ˆæ”¯æŒæ£€æŸ¥ç‚¹å’Œæ¢å¤ï¼‰
- âœ… æµå¼è¾“å‡ºï¼ˆå®æ—¶æŸ¥çœ‹è¿›åº¦ï¼‰
- âœ… LangSmith é›†æˆï¼ˆå¯è§†åŒ–è°ƒè¯•ï¼‰

æŸ¥çœ‹å®Œæ•´æŒ‡å—ï¼š[WORKFLOW_GUIDE.md](./WORKFLOW_GUIDE.md)

### 2. å¤šæ¨¡å‹æ”¯æŒ

æ·»åŠ æ–°çš„ LLM æä¾›å•†ï¼š
```python
# llm/openai.py
class OpenAILLM(BaseLLM):
    async def generate(self, prompt, **kwargs):
        # å®ç° OpenAI è°ƒç”¨é€»è¾‘
        pass
```

åœ¨ factory ä¸­æ³¨å†Œï¼š
```python
# llm/factory.py
elif provider == "openai":
    instance = OpenAILLM(config)
```

### 3. å‘é‡æ•°æ®åº“é›†æˆ

å­˜å‚¨æä»åµŒå…¥ï¼Œæ”¯æŒè¯­ä¹‰æœç´¢ï¼š
```python
from qdrant_client import QdrantClient

# å­˜å‚¨æä»å‘é‡
await vector_db.upsert(
    collection="almonds",
    points=[{
        "id": task_id,
        "vector": embedding,
        "payload": {"title": title, "content": content}
    }]
)

# è¯­ä¹‰æœç´¢ç›¸ä¼¼æä»
similar = await vector_db.search(
    collection="almonds",
    query_vector=query_embedding,
    limit=5
)
```

## ğŸ¤ ä¸ Java æœåŠ¡é›†æˆ

Java æœåŠ¡è°ƒç”¨ç¤ºä¾‹ï¼ˆä½¿ç”¨ä½ æä¾›çš„ä»£ç ï¼‰ï¼š

```java
// 1. è®¾ç½®é…ç½®
@Value("${almond.ai-center.url:http://localhost:8000}")
private String aiCenterUrl;

@Value("${almond.ai-center.token:}")
private String aiCenterToken;

// 2. æ„å»ºè¯·æ±‚
Map<String, Object> request = new HashMap<>();
request.put("title", title);
request.put("content", content);
request.put("task_id", taskId);
request.put("user_id", userId);

// 3. è°ƒç”¨ API
String url = aiCenterUrl + "/v1/ai/analyze/classify";
Map<String, String> headers = new HashMap<>();
headers.put("Content-Type", "application/json");
if (!aiCenterToken.isEmpty()) {
    headers.put("Authorization", "Bearer " + aiCenterToken);
}

HttpRespons response = HttpUtil.postBody(url, JSON.toJSONString(request), headers);
```

## ğŸ“ å¼€å‘æŒ‡å—

### æ·»åŠ æ–°çš„åˆ†æç±»å‹

1. åœ¨ `models/enums.py` æ·»åŠ æšä¸¾
2. åœ¨ `llm/prompts/` åˆ›å»ºæç¤ºè¯æ¨¡æ¿
3. åœ¨ `core/almond_analyzer.py` æ·»åŠ åˆ†ææ–¹æ³•
4. åœ¨ `api/v1/analyze.py` æ·»åŠ è·¯ç”±

### ä»£ç è§„èŒƒ

```bash
# æ ¼å¼åŒ–ä»£ç 
black src/

# æ£€æŸ¥ä»£ç è´¨é‡
ruff check src/

# ç±»å‹æ£€æŸ¥
mypy src/
```

## ğŸ“„ License

MIT

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [QUICKSTART.md](./QUICKSTART.md) - 5åˆ†é’Ÿå¿«é€Ÿå¼€å§‹
- [WORKFLOW_GUIDE.md](./WORKFLOW_GUIDE.md) - å·¥ä½œæµè¯¦ç»†æŒ‡å—
- [CHANGELOG.md](./CHANGELOG.md) - æ›´æ–°æ—¥å¿—

## ğŸ™ è‡´è°¢

åŸºäºæä»äº§å“ç†å¿µè®¾è®¡ï¼Œæ„Ÿè°¢æ‰€æœ‰è´¡çŒ®è€…ã€‚

**æŠ€æœ¯æ ˆ**ï¼š
- FastAPI - ç°ä»£åŒ–çš„ Web æ¡†æ¶
- LangChain 1.0 - LLM åº”ç”¨å¼€å‘æ¡†æ¶
- LangGraph 0.3.1 - å·¥ä½œæµç¼–æ’å¼•æ“
- DashScope - é˜¿é‡Œäº‘å¤§æ¨¡å‹æœåŠ¡
- uv - è¶…å¿«çš„ Python åŒ…ç®¡ç†å™¨